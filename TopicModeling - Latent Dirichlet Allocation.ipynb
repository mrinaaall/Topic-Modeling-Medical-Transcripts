{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Topic Modeling - LDA (Machine Learning Plus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in ./opt/anaconda3/lib/python3.7/site-packages (2.2.3)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in ./opt/anaconda3/lib/python3.7/site-packages (from spacy) (0.0.8)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in ./opt/anaconda3/lib/python3.7/site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in ./opt/anaconda3/lib/python3.7/site-packages (from spacy) (2.0.3)\n",
      "Requirement already satisfied: numpy>=1.15.0 in ./opt/anaconda3/lib/python3.7/site-packages (from spacy) (1.17.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in ./opt/anaconda3/lib/python3.7/site-packages (from spacy) (2.22.0)\n",
      "Requirement already satisfied: srsly<1.1.0,>=0.1.0 in ./opt/anaconda3/lib/python3.7/site-packages (from spacy) (0.2.0)\n",
      "Requirement already satisfied: setuptools in ./opt/anaconda3/lib/python3.7/site-packages (from spacy) (41.4.0)\n",
      "Requirement already satisfied: thinc<7.4.0,>=7.3.0 in ./opt/anaconda3/lib/python3.7/site-packages (from spacy) (7.3.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in ./opt/anaconda3/lib/python3.7/site-packages (from spacy) (1.0.2)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in ./opt/anaconda3/lib/python3.7/site-packages (from spacy) (3.0.2)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in ./opt/anaconda3/lib/python3.7/site-packages (from spacy) (0.4.0)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in ./opt/anaconda3/lib/python3.7/site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in ./opt/anaconda3/lib/python3.7/site-packages (from catalogue<1.1.0,>=0.0.7->spacy) (0.23)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in ./opt/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in ./opt/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./opt/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2019.9.11)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in ./opt/anaconda3/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.8)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in ./opt/anaconda3/lib/python3.7/site-packages (from thinc<7.4.0,>=7.3.0->spacy) (4.36.1)\n",
      "Requirement already satisfied: zipp>=0.5 in ./opt/anaconda3/lib/python3.7/site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (0.6.0)\n",
      "Requirement already satisfied: more-itertools in ./opt/anaconda3/lib/python3.7/site-packages (from zipp>=0.5->importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (7.2.0)\n",
      "Requirement already satisfied: pyLDAvis in ./opt/anaconda3/lib/python3.7/site-packages (2.1.2)\n",
      "Requirement already satisfied: pytest in ./opt/anaconda3/lib/python3.7/site-packages (from pyLDAvis) (5.2.1)\n",
      "Requirement already satisfied: wheel>=0.23.0 in ./opt/anaconda3/lib/python3.7/site-packages (from pyLDAvis) (0.33.6)\n",
      "Requirement already satisfied: numpy>=1.9.2 in ./opt/anaconda3/lib/python3.7/site-packages (from pyLDAvis) (1.17.2)\n",
      "Requirement already satisfied: jinja2>=2.7.2 in ./opt/anaconda3/lib/python3.7/site-packages (from pyLDAvis) (2.10.3)\n",
      "Requirement already satisfied: funcy in ./opt/anaconda3/lib/python3.7/site-packages (from pyLDAvis) (1.13)\n",
      "Requirement already satisfied: scipy>=0.18.0 in ./opt/anaconda3/lib/python3.7/site-packages (from pyLDAvis) (1.3.1)\n",
      "Requirement already satisfied: joblib>=0.8.4 in ./opt/anaconda3/lib/python3.7/site-packages (from pyLDAvis) (0.13.2)\n",
      "Requirement already satisfied: numexpr in ./opt/anaconda3/lib/python3.7/site-packages (from pyLDAvis) (2.7.0)\n",
      "Requirement already satisfied: pandas>=0.17.0 in ./opt/anaconda3/lib/python3.7/site-packages (from pyLDAvis) (0.25.1)\n",
      "Requirement already satisfied: future in ./opt/anaconda3/lib/python3.7/site-packages (from pyLDAvis) (0.17.1)\n",
      "Requirement already satisfied: py>=1.5.0 in ./opt/anaconda3/lib/python3.7/site-packages (from pytest->pyLDAvis) (1.8.0)\n",
      "Requirement already satisfied: packaging in ./opt/anaconda3/lib/python3.7/site-packages (from pytest->pyLDAvis) (19.2)\n",
      "Requirement already satisfied: attrs>=17.4.0 in ./opt/anaconda3/lib/python3.7/site-packages (from pytest->pyLDAvis) (19.2.0)\n",
      "Requirement already satisfied: more-itertools>=4.0.0 in ./opt/anaconda3/lib/python3.7/site-packages (from pytest->pyLDAvis) (7.2.0)\n",
      "Requirement already satisfied: atomicwrites>=1.0 in ./opt/anaconda3/lib/python3.7/site-packages (from pytest->pyLDAvis) (1.3.0)\n",
      "Requirement already satisfied: pluggy<1.0,>=0.12 in ./opt/anaconda3/lib/python3.7/site-packages (from pytest->pyLDAvis) (0.13.0)\n",
      "Requirement already satisfied: wcwidth in ./opt/anaconda3/lib/python3.7/site-packages (from pytest->pyLDAvis) (0.1.7)\n",
      "Requirement already satisfied: importlib-metadata>=0.12 in ./opt/anaconda3/lib/python3.7/site-packages (from pytest->pyLDAvis) (0.23)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in ./opt/anaconda3/lib/python3.7/site-packages (from jinja2>=2.7.2->pyLDAvis) (1.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in ./opt/anaconda3/lib/python3.7/site-packages (from pandas>=0.17.0->pyLDAvis) (2.8.0)\n",
      "Requirement already satisfied: pytz>=2017.2 in ./opt/anaconda3/lib/python3.7/site-packages (from pandas>=0.17.0->pyLDAvis) (2019.3)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in ./opt/anaconda3/lib/python3.7/site-packages (from packaging->pytest->pyLDAvis) (2.4.2)\n",
      "Requirement already satisfied: six in ./opt/anaconda3/lib/python3.7/site-packages (from packaging->pytest->pyLDAvis) (1.12.0)\n",
      "Requirement already satisfied: zipp>=0.5 in ./opt/anaconda3/lib/python3.7/site-packages (from importlib-metadata>=0.12->pytest->pyLDAvis) (0.6.0)\n",
      "Requirement already satisfied: regex in ./opt/anaconda3/lib/python3.7/site-packages (2019.11.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy\n",
    "!pip install pyLDAvis\n",
    "!pip install regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/mrinal/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk; nltk.download('stopwords')\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim.models.wrappers import LdaMallet\n",
    "import os\n",
    "os.environ.update({'MALLET_HOME':r'Users/mrinal/Downloads/mallet-2.0.8/'})\n",
    "\n",
    "import spacy\n",
    "\n",
    "# Plotting tools\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim  # don't skip this\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing stopwords:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "__mtData = pd.read_csv('/Users/mrinal/Downloads/mtsamples.csv', error_bad_lines = False)\n",
    "__mtText = __mtData[['transcription']]\n",
    "__naText = __mtText.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting String to List:\n",
    "__mtList = __mtText.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize words and clean up text:\n",
    "def sentenceToWords(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n",
    "\n",
    "__mtWords = list(sentenceToWords(__mtList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['subjective', 'this', 'year', 'old', 'white', 'female', 'presents', 'with', 'complaint', 'of', 'allergies', 'she', 'used', 'to', 'have', 'allergies', 'when', 'she', 'lived', 'in', 'seattle', 'but', 'she', 'thinks', 'they', 'are', 'worse', 'here', 'in', 'the', 'past', 'she', 'has', 'tried', 'claritin', 'and', 'zyrtec', 'both', 'worked', 'for', 'short', 'time', 'but', 'then', 'seemed', 'to', 'lose', 'effectiveness', 'she', 'has', 'used', 'allegra', 'also', 'she', 'used', 'that', 'last', 'summer', 'and', 'she', 'began', 'using', 'it', 'again', 'two', 'weeks', 'ago', 'it', 'does', 'not', 'appear', 'to', 'be', 'working', 'very', 'well', 'she', 'has', 'used', 'over', 'the', 'counter', 'sprays', 'but', 'no', 'prescription', 'nasal', 'sprays', 'she', 'does', 'have', 'asthma', 'but', 'doest', 'not', 'require', 'daily', 'medication', 'for', 'this', 'and', 'does', 'not', 'think', 'it', 'is', 'flaring', 'up', 'medications', 'her', 'only', 'medication', 'currently', 'is', 'ortho', 'tri', 'cyclen', 'and', 'the', 'allegra', 'allergies', 'she', 'has', 'no', 'known', 'medicine', 'allergies', 'objective', 'vitals', 'weight', 'was', 'pounds', 'and', 'blood', 'pressure', 'heent', 'her', 'throat', 'was', 'mildly', 'erythematous', 'without', 'exudate', 'nasal', 'mucosa', 'was', 'erythematous', 'and', 'swollen', 'only', 'clear', 'drainage', 'was', 'seen', 'tms', 'were', 'clear', 'neck', 'supple', 'without', 'adenopathy', 'lungs', 'clear', 'assessment', 'allergic', 'rhinitis', 'plan', 'she', 'will', 'try', 'zyrtec', 'instead', 'of', 'allegra', 'again', 'another', 'option', 'will', 'be', 'to', 'use', 'loratadine', 'she', 'does', 'not', 'think', 'she', 'has', 'prescription', 'coverage', 'so', 'that', 'might', 'be', 'cheaper', 'samples', 'of', 'nasonex', 'two', 'sprays', 'in', 'each', 'nostril', 'given', 'for', 'three', 'weeks', 'prescription', 'was', 'written', 'as', 'well'] \n",
      "\n",
      "['past', 'medical', 'history', 'he', 'has', 'difficulty', 'climbing', 'stairs', 'difficulty', 'with', 'airline', 'seats', 'tying', 'shoes', 'used', 'to', 'public', 'seating', 'and', 'lifting', 'objects', 'off', 'the', 'floor', 'he', 'exercises', 'three', 'times', 'week', 'at', 'home', 'and', 'does', 'cardio', 'he', 'has', 'difficulty', 'walking', 'two', 'blocks', 'or', 'five', 'flights', 'of', 'stairs', 'difficulty', 'with', 'snoring', 'he', 'has', 'muscle', 'and', 'joint', 'pains', 'including', 'knee', 'pain', 'back', 'pain', 'foot', 'and', 'ankle', 'pain', 'and', 'swelling', 'he', 'has', 'reflux', 'disease', 'past', 'surgical', 'history', 'includes', 'reconstructive', 'surgery', 'on', 'his', 'right', 'hand', 'years', 'ago', 'social', 'history', 'he', 'is', 'currently', 'single', 'he', 'has', 'about', 'ten', 'drinks', 'year', 'he', 'had', 'smoked', 'significantly', 'up', 'until', 'several', 'months', 'ago', 'he', 'now', 'smokes', 'less', 'than', 'three', 'cigarettes', 'day', 'family', 'history', 'heart', 'disease', 'in', 'both', 'grandfathers', 'grandmother', 'with', 'stroke', 'and', 'grandmother', 'with', 'diabetes', 'denies', 'obesity', 'and', 'hypertension', 'in', 'other', 'family', 'members', 'current', 'medications', 'none', 'allergies', 'he', 'is', 'allergic', 'to', 'penicillin', 'miscellaneous', 'eating', 'history', 'he', 'has', 'been', 'going', 'to', 'support', 'groups', 'for', 'seven', 'months', 'with', 'lynn', 'holmberg', 'in', 'greenwich', 'and', 'he', 'is', 'from', 'eastchester', 'new', 'york', 'and', 'he', 'feels', 'that', 'we', 'are', 'the', 'appropriate', 'program', 'he', 'had', 'poor', 'experience', 'with', 'the', 'greenwich', 'program', 'eating', 'history', 'he', 'is', 'not', 'an', 'emotional', 'eater', 'does', 'not', 'like', 'sweets', 'he', 'likes', 'big', 'portions', 'and', 'carbohydrates', 'he', 'likes', 'chicken', 'and', 'not', 'steak', 'he', 'currently', 'weighs', 'pounds', 'ideal', 'body', 'weight', 'would', 'be', 'pounds', 'he', 'is', 'pounds', 'overweight', 'if', 'he', 'lost', 'of', 'his', 'excess', 'body', 'weight', 'that', 'would', 'be', 'pounds', 'and', 'he', 'should', 'weigh', 'about', 'review', 'of', 'systems', 'negative', 'for', 'head', 'neck', 'heart', 'lungs', 'gi', 'gu', 'orthopedic', 'and', 'skin', 'specifically', 'denies', 'chest', 'pain', 'heart', 'attack', 'coronary', 'artery', 'disease', 'congestive', 'heart', 'failure', 'arrhythmia', 'atrial', 'fibrillation', 'pacemaker', 'high', 'cholesterol', 'pulmonary', 'embolism', 'high', 'blood', 'pressure', 'cva', 'venous', 'insufficiency', 'asthma', 'shortness', 'of', 'breath', 'copd', 'emphysema', 'sleep', 'apnea', 'diabetes', 'leg', 'and', 'foot', 'swelling', 'osteoarthritis', 'rheumatoid', 'arthritis', 'hiatal', 'hernia', 'peptic', 'ulcer', 'disease', 'gallstones', 'infected', 'gallbladder', 'pancreatitis', 'fatty', 'liver', 'hepatitis', 'hemorrhoids', 'rectal', 'bleeding', 'polyps', 'incontinence', 'of', 'stool', 'urinary', 'stress', 'incontinence', 'or', 'cancer', 'denies', 'cellulitis', 'pseudotumor', 'cerebri', 'meningitis', 'or', 'encephalitis', 'physical', 'examination', 'he', 'is', 'alert', 'and', 'oriented', 'cranial', 'nerves', 'ii', 'xii', 'are', 'intact', 'afebrile', 'vital', 'signs', 'are', 'stable'] \n",
      "\n",
      "['history', 'of', 'present', 'illness', 'have', 'seen', 'abc', 'today', 'he', 'is', 'very', 'pleasant', 'gentleman', 'who', 'is', 'years', 'old', 'pounds', 'he', 'is', 'he', 'has', 'bmi', 'of', 'he', 'has', 'been', 'overweight', 'for', 'ten', 'years', 'since', 'the', 'age', 'of', 'at', 'his', 'highest', 'he', 'was', 'pounds', 'at', 'his', 'lowest', 'he', 'is', 'pursuing', 'surgical', 'attempts', 'of', 'weight', 'loss', 'to', 'feel', 'good', 'get', 'healthy', 'and', 'begin', 'to', 'exercise', 'again', 'he', 'wants', 'to', 'be', 'able', 'to', 'exercise', 'and', 'play', 'volleyball', 'physically', 'he', 'is', 'sluggish', 'he', 'gets', 'tired', 'quickly', 'he', 'does', 'not', 'go', 'out', 'often', 'when', 'he', 'loses', 'weight', 'he', 'always', 'regains', 'it', 'and', 'he', 'gains', 'back', 'more', 'than', 'he', 'lost', 'his', 'biggest', 'weight', 'loss', 'is', 'pounds', 'and', 'it', 'was', 'three', 'months', 'before', 'he', 'gained', 'it', 'back', 'he', 'did', 'six', 'months', 'of', 'not', 'drinking', 'alcohol', 'and', 'not', 'taking', 'in', 'many', 'calories', 'he', 'has', 'been', 'on', 'multiple', 'commercial', 'weight', 'loss', 'programs', 'including', 'slim', 'fast', 'for', 'one', 'month', 'one', 'year', 'ago', 'and', 'atkin', 'diet', 'for', 'one', 'month', 'two', 'years', 'ago', 'past', 'medical', 'history', 'he', 'has', 'difficulty', 'climbing', 'stairs', 'difficulty', 'with', 'airline', 'seats', 'tying', 'shoes', 'used', 'to', 'public', 'seating', 'difficulty', 'walking', 'high', 'cholesterol', 'and', 'high', 'blood', 'pressure', 'he', 'has', 'asthma', 'and', 'difficulty', 'walking', 'two', 'blocks', 'or', 'going', 'eight', 'to', 'ten', 'steps', 'he', 'has', 'sleep', 'apnea', 'and', 'snoring', 'he', 'is', 'diabetic', 'on', 'medication', 'he', 'has', 'joint', 'pain', 'knee', 'pain', 'back', 'pain', 'foot', 'and', 'ankle', 'pain', 'leg', 'and', 'foot', 'swelling', 'he', 'has', 'hemorrhoids', 'past', 'surgical', 'history', 'includes', 'orthopedic', 'or', 'knee', 'surgery', 'social', 'history', 'he', 'is', 'currently', 'single', 'he', 'drinks', 'alcohol', 'ten', 'to', 'twelve', 'drinks', 'week', 'but', 'does', 'not', 'drink', 'five', 'days', 'week', 'and', 'then', 'will', 'binge', 'drink', 'he', 'smokes', 'one', 'and', 'half', 'pack', 'day', 'for', 'years', 'but', 'he', 'has', 'recently', 'stopped', 'smoking', 'for', 'the', 'past', 'two', 'weeks', 'family', 'history', 'obesity', 'heart', 'disease', 'and', 'diabetes', 'family', 'history', 'is', 'negative', 'for', 'hypertension', 'and', 'stroke', 'current', 'medications', 'include', 'diovan', 'crestor', 'and', 'tricor', 'miscellaneous', 'eating', 'history', 'he', 'says', 'couple', 'of', 'friends', 'of', 'his', 'have', 'had', 'heart', 'attacks', 'and', 'have', 'had', 'died', 'he', 'used', 'to', 'drink', 'everyday', 'but', 'stopped', 'two', 'years', 'ago', 'he', 'now', 'only', 'drinks', 'on', 'weekends', 'he', 'is', 'on', 'his', 'second', 'week', 'of', 'chantix', 'which', 'is', 'medication', 'to', 'come', 'off', 'smoking', 'completely', 'eating', 'he', 'eats', 'bad', 'food', 'he', 'is', 'single', 'he', 'eats', 'things', 'like', 'bacon', 'eggs', 'and', 'cheese', 'cheeseburgers', 'fast', 'food', 'eats', 'four', 'times', 'day', 'seven', 'in', 'the', 'morning', 'at', 'noon', 'and', 'he', 'currently', 'weighs', 'pounds', 'and', 'his', 'ideal', 'body', 'weight', 'is', 'pounds', 'he', 'is', 'pounds', 'overweight', 'if', 'he', 'lost', 'of', 'his', 'excess', 'body', 'weight', 'that', 'would', 'be', 'pounds', 'and', 'that', 'would', 'get', 'him', 'down', 'to', 'review', 'of', 'systems', 'negative', 'for', 'head', 'neck', 'heart', 'lungs', 'gi', 'gu', 'orthopedic', 'or', 'skin', 'he', 'also', 'is', 'positive', 'for', 'gout', 'he', 'denies', 'chest', 'pain', 'heart', 'attack', 'coronary', 'artery', 'disease', 'congestive', 'heart', 'failure', 'arrhythmia', 'atrial', 'fibrillation', 'pacemaker', 'pulmonary', 'embolism', 'or', 'cva', 'he', 'denies', 'venous', 'insufficiency', 'or', 'denies', 'shortness', 'of', 'breath', 'copd', 'or', 'emphysema', 'denies', 'thyroid', 'problems', 'hip', 'pain', 'osteoarthritis', 'rheumatoid', 'arthritis', 'gerd', 'hiatal', 'hernia', 'peptic', 'ulcer', 'disease', 'gallstones', 'infected', 'gallbladder', 'pancreatitis', 'fatty', 'liver', 'hepatitis', 'rectal', 'bleeding', 'polyps', 'incontinence', 'of', 'stool', 'urinary', 'stress', 'incontinence', 'or', 'cancer', 'he', 'denies', 'cellulitis', 'pseudotumor', 'cerebri', 'meningitis', 'or', 'encephalitis', 'physical', 'examination', 'he', 'is', 'alert', 'and', 'oriented', 'cranial', 'nerves', 'ii', 'xii', 'are', 'intact', 'neck', 'is', 'soft', 'and', 'supple', 'lungs', 'he', 'has', 'positive', 'wheezing', 'bilaterally', 'heart', 'is', 'regular', 'rhythm', 'and', 'rate', 'his', 'abdomen', 'is', 'soft', 'extremities', 'he', 'has', 'pitting', 'edema', 'impression', 'plan', 'have', 'explained', 'to', 'him', 'the', 'risks', 'and', 'potential', 'complications', 'of', 'laparoscopic', 'gastric', 'bypass', 'in', 'detail', 'and', 'these', 'include', 'bleeding', 'infection', 'deep', 'venous', 'thrombosis', 'pulmonary', 'embolism', 'leakage', 'from', 'the', 'gastrojejuno', 'anastomosis', 'jejunojejuno', 'anastomosis', 'and', 'possible', 'bowel', 'obstruction', 'among', 'other', 'potential', 'complications', 'he', 'understands', 'he', 'wants', 'to', 'proceed', 'with', 'workup', 'and', 'evaluation', 'for', 'laparoscopic', 'roux', 'en', 'gastric', 'bypass', 'he', 'will', 'need', 'to', 'get', 'letter', 'of', 'approval', 'from', 'dr', 'xyz', 'he', 'will', 'need', 'to', 'see', 'nutritionist', 'and', 'mental', 'health', 'worker', 'he', 'will', 'need', 'an', 'upper', 'endoscopy', 'by', 'either', 'dr', 'xyz', 'he', 'will', 'need', 'to', 'go', 'to', 'dr', 'xyz', 'as', 'he', 'previously', 'had', 'sleep', 'study', 'we', 'will', 'need', 'another', 'sleep', 'study', 'he', 'will', 'need', 'pylori', 'testing', 'thyroid', 'function', 'tests', 'lfts', 'glycosylated', 'hemoglobin', 'and', 'fasting', 'blood', 'sugar', 'after', 'this', 'is', 'performed', 'we', 'will', 'submit', 'him', 'for', 'insurance', 'approval'] \n",
      "\n",
      "['mode', 'left', 'atrial', 'enlargement', 'with', 'left', 'atrial', 'diameter', 'of', 'cm', 'normal', 'size', 'right', 'and', 'left', 'ventricle', 'normal', 'lv', 'systolic', 'function', 'with', 'left', 'ventricular', 'ejection', 'fraction', 'of', 'normal', 'lv', 'diastolic', 'function', 'no', 'pericardial', 'effusion', 'normal', 'morphology', 'of', 'aortic', 'valve', 'mitral', 'valve', 'tricuspid', 'valve', 'and', 'pulmonary', 'valve', 'pa', 'systolic', 'pressure', 'is', 'mmhg', 'doppler', 'mild', 'mitral', 'and', 'tricuspid', 'regurgitation', 'trace', 'aortic', 'and', 'pulmonary', 'regurgitation'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Printing the words obtained:\n",
    "for i in range(0, len(__mtWords)//1000):\n",
    "    print(__mtWords[i], '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminate stopwords, make bigrams and lemmatize:\n",
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
    "\n",
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    return texts_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['subjective', 'year', 'old', 'white', 'female', 'present', 'complaint', 'allergy', 'use', 'allergy', 'live', 'think', 'bad', 'past', 'try', 'claritin', 'zyrtec', 'work', 'short', 'time', 'seem', 'lose', 'effectiveness', 'use', 'allegra', 'also', 'use', 'last', 'summer', 'begin', 'use', 'week', 'ago', 'appear', 'work', 'well', 'use', 'counter', 'spray', 'prescription', 'nasal', 'spray', 'asthma', 'do', 'require', 'daily', 'medication', 'think', 'flare', 'medication', 'medication', 'currently', 'ortho', 'allergie', 'know', 'medicine', 'allergy', 'objective', 'vital', 'weight', 'pound', 'blood', 'pressure', 'heent', 'throat', 'mildly', 'erythematous', 'exudate', 'nasal', 'mucosa', 'erythematous', 'swollen', 'clear', 'drainage', 'see', 'clear', 'neck', 'supple', 'adenopathy', 'lung', 'clear', 'assessment', 'allergic', 'rhinitis', 'plan', 'try', 'zyrtec', 'instead', 'allegra', 'option', 'use', 'loratadine', 'think', 'prescription', 'coverage', 'may', 'cheap', 'sample', 'spray', 'give', 'week', 'prescription', 'write', 'well']]\n"
     ]
    }
   ],
   "source": [
    "# Remove Stop Words\n",
    "__noStopWords = remove_stopwords(__mtWords)\n",
    "nlp = spacy.load('en', disable=['parser', 'ner'])\n",
    "\n",
    "# Do lemmatization keeping only noun, adj, vb, adv\n",
    "__lemmData = lemmatization(__noStopWords, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
    "\n",
    "print(__lemmData[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 1), (1, 1), (2, 2), (3, 1), (4, 1), (5, 3), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 3), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 1), (23, 1), (24, 2), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1), (33, 1), (34, 1), (35, 1), (36, 1), (37, 1), (38, 3), (39, 1), (40, 1), (41, 1), (42, 2), (43, 1), (44, 1), (45, 1), (46, 1), (47, 1), (48, 1), (49, 1), (50, 1), (51, 3), (52, 1), (53, 1), (54, 1), (55, 1), (56, 1), (57, 1), (58, 1), (59, 1), (60, 3), (61, 1), (62, 1), (63, 1), (64, 1), (65, 3), (66, 1), (67, 1), (68, 2), (69, 6), (70, 1), (71, 2), (72, 1), (73, 2), (74, 1), (75, 2), (76, 1), (77, 1), (78, 2)]]\n"
     ]
    }
   ],
   "source": [
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(__lemmData)\n",
    "\n",
    "# Create Corpus\n",
    "__textCorpus = __lemmData\n",
    "\n",
    "# Term Document Frequency\n",
    "__corpus = [__id2word.doc2bow(text) for text in __textCorpus]\n",
    "\n",
    "print(__corpus[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('adenopathy', 1),\n",
       "  ('ago', 1),\n",
       "  ('allegra', 2),\n",
       "  ('allergic', 1),\n",
       "  ('allergie', 1),\n",
       "  ('allergy', 3),\n",
       "  ('also', 1),\n",
       "  ('appear', 1),\n",
       "  ('assessment', 1),\n",
       "  ('asthma', 1),\n",
       "  ('bad', 1),\n",
       "  ('begin', 1),\n",
       "  ('blood', 1),\n",
       "  ('cheap', 1),\n",
       "  ('claritin', 1),\n",
       "  ('clear', 3),\n",
       "  ('complaint', 1),\n",
       "  ('counter', 1),\n",
       "  ('coverage', 1),\n",
       "  ('currently', 1),\n",
       "  ('daily', 1),\n",
       "  ('do', 1),\n",
       "  ('drainage', 1),\n",
       "  ('effectiveness', 1),\n",
       "  ('erythematous', 2),\n",
       "  ('exudate', 1),\n",
       "  ('female', 1),\n",
       "  ('flare', 1),\n",
       "  ('give', 1),\n",
       "  ('heent', 1),\n",
       "  ('instead', 1),\n",
       "  ('know', 1),\n",
       "  ('last', 1),\n",
       "  ('live', 1),\n",
       "  ('loratadine', 1),\n",
       "  ('lose', 1),\n",
       "  ('lung', 1),\n",
       "  ('may', 1),\n",
       "  ('medication', 3),\n",
       "  ('medicine', 1),\n",
       "  ('mildly', 1),\n",
       "  ('mucosa', 1),\n",
       "  ('nasal', 2),\n",
       "  ('neck', 1),\n",
       "  ('objective', 1),\n",
       "  ('old', 1),\n",
       "  ('option', 1),\n",
       "  ('ortho', 1),\n",
       "  ('past', 1),\n",
       "  ('plan', 1),\n",
       "  ('pound', 1),\n",
       "  ('prescription', 3),\n",
       "  ('present', 1),\n",
       "  ('pressure', 1),\n",
       "  ('require', 1),\n",
       "  ('rhinitis', 1),\n",
       "  ('sample', 1),\n",
       "  ('see', 1),\n",
       "  ('seem', 1),\n",
       "  ('short', 1),\n",
       "  ('spray', 3),\n",
       "  ('subjective', 1),\n",
       "  ('summer', 1),\n",
       "  ('supple', 1),\n",
       "  ('swollen', 1),\n",
       "  ('think', 3),\n",
       "  ('throat', 1),\n",
       "  ('time', 1),\n",
       "  ('try', 2),\n",
       "  ('use', 6),\n",
       "  ('vital', 1),\n",
       "  ('week', 2),\n",
       "  ('weight', 1),\n",
       "  ('well', 2),\n",
       "  ('white', 1),\n",
       "  ('work', 2),\n",
       "  ('write', 1),\n",
       "  ('year', 1),\n",
       "  ('zyrtec', 2)]]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Human readable format of corpus (term-frequency)\n",
    "[[(__id2word[id], freq) for id, freq in cp] for cp in __corpus[:1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build LDA model\n",
    "__ldaModel = gensim.models.ldamodel.LdaModel(corpus = __corpus,\n",
    "                                           id2word = __id2word,\n",
    "                                           num_topics = 10, \n",
    "                                           random_state = 100,\n",
    "                                           update_every = 1,\n",
    "                                           chunksize = 100,\n",
    "                                           passes = 10,\n",
    "                                           alpha = 'auto',\n",
    "                                           per_word_topics = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.033*\"right\" + 0.023*\"extremity\" + 0.021*\"normal\" + 0.021*\"low\" + '\n",
      "  '0.018*\"leave\" + 0.016*\"pain\" + 0.015*\"knee\" + 0.014*\"reveal\" + '\n",
      "  '0.011*\"motion\" + 0.011*\"upper\"'),\n",
      " (1,\n",
      "  '0.027*\"place\" + 0.025*\"suture\" + 0.021*\"incision\" + 0.018*\"use\" + '\n",
      "  '0.016*\"skin\" + 0.015*\"close\" + 0.013*\"patient\" + 0.012*\"run\" + '\n",
      "  '0.011*\"fashion\" + 0.011*\"dissection\"'),\n",
      " (2,\n",
      "  '0.037*\"history\" + 0.019*\"patient\" + 0.012*\"year\" + 0.010*\"normal\" + '\n",
      "  '0.010*\"pain\" + 0.009*\"deny\" + 0.009*\"medication\" + 0.009*\"blood\" + '\n",
      "  '0.007*\"present\" + 0.007*\"medical\"'),\n",
      " (3,\n",
      "  '0.064*\"cord\" + 0.041*\"nonspecific\" + 0.032*\"detect\" + 0.025*\"postprocedure\" '\n",
      "  '+ 0.024*\"penis\" + 0.024*\"inguinal\" + 0.024*\"testicle\" + 0.019*\"hernia\" + '\n",
      "  '0.017*\"vasculature\" + 0.017*\"milk\"'),\n",
      " (4,\n",
      "  '0.040*\"normal\" + 0.021*\"lesion\" + 0.019*\"leave\" + 0.019*\"breast\" + '\n",
      "  '0.018*\"right\" + 0.014*\"appear\" + 0.014*\"note\" + 0.013*\"tumor\" + '\n",
      "  '0.011*\"evidence\" + 0.011*\"small\"'),\n",
      " (5,\n",
      "  '0.054*\"procedure\" + 0.048*\"patient\" + 0.022*\"remove\" + 0.022*\"place\" + '\n",
      "  '0.020*\"use\" + 0.014*\"perform\" + 0.012*\"complication\" + 0.011*\"room\" + '\n",
      "  '0.009*\"position\" + 0.009*\"area\"'),\n",
      " (6,\n",
      "  '0.043*\"leave\" + 0.039*\"artery\" + 0.033*\"right\" + 0.023*\"coronary\" + '\n",
      "  '0.013*\"pulmonary\" + 0.012*\"pressure\" + 0.011*\"normal\" + 0.011*\"atrial\" + '\n",
      "  '0.010*\"stenosis\" + 0.010*\"chest\"'),\n",
      " (7,\n",
      "  '0.022*\"discharge\" + 0.015*\"low\" + 0.014*\"acute\" + 0.013*\"admission\" + '\n",
      "  '0.012*\"chronic\" + 0.012*\"hospital\" + 0.011*\"course\" + 0.011*\"secondary\" + '\n",
      "  '0.010*\"fluid\" + 0.010*\"renal\"'),\n",
      " (8,\n",
      "  '0.077*\"patient\" + 0.019*\"also\" + 0.017*\"time\" + 0.013*\"need\" + '\n",
      "  '0.013*\"would\" + 0.013*\"pain\" + 0.010*\"give\" + 0.010*\"go\" + 0.010*\"surgery\" '\n",
      "  '+ 0.010*\"discuss\"'),\n",
      " (9,\n",
      "  '0.019*\"leave\" + 0.017*\"right\" + 0.011*\"use\" + 0.009*\"fracture\" + '\n",
      "  '0.009*\"lateral\" + 0.008*\"neck\" + 0.008*\"inch\" + 0.008*\"area\" + '\n",
      "  '0.007*\"nerve\" + 0.007*\"hear\"')]\n"
     ]
    }
   ],
   "source": [
    "# Print the Keyword in the 10 topics\n",
    "pprint(__ldaModel.print_topics())\n",
    "__documentsLDA = __ldaModel[__corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.35478094, 0.17508884, 1.0247076 , 0.04860025, 0.31675854,\n",
       "       0.42144945, 0.42239565, 0.41841653, 0.60486555, 0.4516257 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(__ldaModel.alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A range of alpha values obtained using the 'auto' parameter in LdaModel where the model gives ideal values of alpha to obtain the number of topics listed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Coherence Score:  0.5334579607285418\n"
     ]
    }
   ],
   "source": [
    "# # Compute Perplexity\n",
    "# print('\\nPerplexity: ', lda_model.log_perplexity(corpus))  # a measure of how good the model is. lower the better.\n",
    "\n",
    "# Compute Coherence Score\n",
    "__coherenceModel = CoherenceModel(model = __ldaModel, texts = __lemmData, dictionary = __id2word, coherence = 'c_v')\n",
    "__ldaCoherence = __coherenceModel.get_coherence()\n",
    "print('\\nCoherence Score: ', __ldaCoherence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mrinal/opt/anaconda3/lib/python3.7/site-packages/pyLDAvis/_prepare.py:257: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  return pd.concat([default_term_info] + list(topic_dfs))\n"
     ]
    }
   ],
   "source": [
    "# Visualize the topics\n",
    "pyLDAvis.enable_notebook()\n",
    "__vis = pyLDAvis.gensim.prepare(__ldaModel, __corpus, __id2word)\n",
    "# __vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_coherence_values(dictionary, corpus, texts, limit, start = 2, step = 3):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    ----------\n",
    "    dictionary : Gensim dictionary\n",
    "    corpus : Gensim corpus\n",
    "    texts : List of input texts\n",
    "    limit : Max num of topics\n",
    "    \n",
    "    Returns:\n",
    "    -------\n",
    "    model_list : List of LDA topic models\n",
    "    coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n",
    "    \"\"\"\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    for num_topics in range(start, limit, step):\n",
    "        model = gensim.models.wrappers.LdaMallet(mallet_path, corpus = __corpus, num_topics = num_topics, id2word = id2word)\n",
    "        model_list.append(model)\n",
    "        coherencemodel = CoherenceModel(model = model, texts = __textCorpus, dictionary = dictionary, coherence = 'c_v')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "\n",
    "    return model_list, coherence_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mallet_path = 'Users/mrinal/Downloads/mallet-2.0.8/bin/mallet' # update this path\n",
    "import os\n",
    "os.environ.update({'MALLET_HOME':r'/Users/mrinal/Downloads/mallet-2.0.8/bin/mallet'})\n",
    "\n",
    "__malletPath = '/Users/mrinal/Downloads/mallet-2.0.8/bin/mallet' # update this path\n",
    "__ldamallet = gensim.models.wrappers.LdaMallet(__malletPath, corpus = __corpus, num_topics = 10, id2word = __id2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  [('skin', 0.01788552871534313),\n",
      "   ('patient', 0.017641723798285564),\n",
      "   ('incision', 0.016061867935752528),\n",
      "   ('leave', 0.015057391677475352),\n",
      "   ('tissue', 0.012453555163300533),\n",
      "   ('area', 0.011371061331564935),\n",
      "   ('procedure', 0.01128329156142421),\n",
      "   ('foot', 0.010473859236793087),\n",
      "   ('lateral', 0.00917681707804683),\n",
      "   ('perform', 0.009118303897953014)]),\n",
      " (1,\n",
      "  [('place', 0.029313638324281025),\n",
      "   ('suture', 0.02033468604477152),\n",
      "   ('incision', 0.016716696449792692),\n",
      "   ('close', 0.012130388471729505),\n",
      "   ('procedure', 0.012024753739029392),\n",
      "   ('patient', 0.011602214808228945),\n",
      "   ('fashion', 0.010853968784936488),\n",
      "   ('remove', 0.010801151418586431),\n",
      "   ('make', 0.00966557804206023),\n",
      "   ('tube', 0.008274720728175424)]),\n",
      " (2,\n",
      "  [('patient', 0.06146431405498763),\n",
      "   ('procedure', 0.045220090556878124),\n",
      "   ('risk', 0.014096998552957101),\n",
      "   ('eye', 0.013746907529290949),\n",
      "   ('place', 0.012066470615693414),\n",
      "   ('remove', 0.011447976473883209),\n",
      "   ('room', 0.011401297670727723),\n",
      "   ('diagnosis', 0.011074546048639312),\n",
      "   ('complication', 0.010059282080007469),\n",
      "   ('obtain', 0.009067357512953367)]),\n",
      " (3,\n",
      "  [('normal', 0.029487300157319384),\n",
      "   ('leave', 0.02037084347393473),\n",
      "   ('evidence', 0.017990883543316617),\n",
      "   ('finding', 0.01362090061986527),\n",
      "   ('tumor', 0.013540224012047707),\n",
      "   ('small', 0.013446101302927217),\n",
      "   ('lesion', 0.011698108133546678),\n",
      "   ('breast', 0.0107703271436447),\n",
      "   ('mass', 0.010447620712374447),\n",
      "   ('low', 0.008834088556023181)]),\n",
      " (4,\n",
      "  [('place', 0.026753737153534723),\n",
      "   ('patient', 0.011824587355963874),\n",
      "   ('remove', 0.010179850513858611),\n",
      "   ('position', 0.010121457489878543),\n",
      "   ('fracture', 0.0098294923699782),\n",
      "   ('anterior', 0.009333151666147618),\n",
      "   ('posterior', 0.008525381501090003),\n",
      "   ('perform', 0.007668950482715665),\n",
      "   ('screw', 0.007600825288072251),\n",
      "   ('lateral', 0.0073964497041420114)]),\n",
      " (5,\n",
      "  [('patient', 0.04469572525499484),\n",
      "   ('year', 0.017687282729113345),\n",
      "   ('time', 0.017601329411315276),\n",
      "   ('history', 0.016799098445199986),\n",
      "   ('report', 0.015557550521450128),\n",
      "   ('state', 0.009875081178133476),\n",
      "   ('day', 0.009263857584902778),\n",
      "   ('week', 0.008690835466248997),\n",
      "   ('problem', 0.008423425144210567),\n",
      "   ('plan', 0.007525690491652978)]),\n",
      " (6,\n",
      "  [('patient', 0.048605749376043665),\n",
      "   ('history', 0.027346345142118398),\n",
      "   ('blood', 0.017596466342269225),\n",
      "   ('discharge', 0.014023306340114557),\n",
      "   ('day', 0.011958414881582963),\n",
      "   ('disease', 0.011114502720270052),\n",
      "   ('show', 0.011069613775519365),\n",
      "   ('present', 0.010082056991004255),\n",
      "   ('time', 0.009731923221948898),\n",
      "   ('continue', 0.009202233673890794)]),\n",
      " (7,\n",
      "  [('pain', 0.03389316066369891),\n",
      "   ('leave', 0.018059490084985835),\n",
      "   ('low', 0.01529745042492918),\n",
      "   ('extremity', 0.014639821934439499),\n",
      "   ('reveal', 0.01415418858761635),\n",
      "   ('normal', 0.009894779441521652),\n",
      "   ('symptom', 0.009166329421286928),\n",
      "   ('leg', 0.0080230675839741),\n",
      "   ('examination', 0.007992715499797652),\n",
      "   ('time', 0.007891541885876164)]),\n",
      " (8,\n",
      "  [('history', 0.03497930487512702),\n",
      "   ('normal', 0.02739522318514908),\n",
      "   ('negative', 0.014903794519303057),\n",
      "   ('deny', 0.01268144378444024),\n",
      "   ('clear', 0.012152706063134589),\n",
      "   ('patient', 0.01134307642738531),\n",
      "   ('pain', 0.010789554125393456),\n",
      "   ('neck', 0.010789554125393456),\n",
      "   ('note', 0.00970729410209595),\n",
      "   ('examination', 0.009492494402815528)]),\n",
      " (9,\n",
      "  [('leave', 0.050560152302848355),\n",
      "   ('artery', 0.03644040906982988),\n",
      "   ('coronary', 0.017597813087305656),\n",
      "   ('catheter', 0.01460789338800615),\n",
      "   ('pressure', 0.014290595787264163),\n",
      "   ('normal', 0.010800322179102291),\n",
      "   ('perform', 0.010641673378731297),\n",
      "   ('patient', 0.010470820824485612),\n",
      "   ('stenosis', 0.010055893192746088),\n",
      "   ('pulmonary', 0.009348075468013962)])]\n",
      "\n",
      "Coherence Score:  0.559577449723782\n"
     ]
    }
   ],
   "source": [
    "# Topics with their corresponding probabilities\n",
    "pprint(__ldamallet.show_topics(formatted = False))\n",
    "\n",
    "# Computing Coherence Score\n",
    "__coherenceMallet = CoherenceModel(model = __ldamallet, texts = __lemmData, dictionary = __id2word, coherence = 'c_v')\n",
    "__coherenceLdaMallet = __coherenceMallet.get_coherence()\n",
    "print('\\nCoherence Score: ', __coherenceLdaMallet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coherence Score (using LdaMallet) for a range of values - takes forever to run.\n",
    "model_list, coherence_values = compute_coherence_values(dictionary = __id2word, corpus = __corpus, texts = __lemmData, start = 2, limit = 20, step = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting graph for range of Cohernece Values\"\n",
    "limit = 20; start = 2; step = 1;\n",
    "\n",
    "x = range(start, limit, step)\n",
    "\n",
    "plt.plot(x, coherence_values)\n",
    "\n",
    "plt.xlabel(\"Number of Topics\")\n",
    "plt.ylabel(\"Coherence score\")\n",
    "plt.legend((\"coherence_values\"), loc = 'best')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
